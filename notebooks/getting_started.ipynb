{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Speaker Recognition System - Getting Started\n",
        "\n",
        "This notebook demonstrates the basic usage of the Speaker Recognition System."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from data.database import SpeakerDatabase\n",
        "from data.audio_processor import AudioProcessor\n",
        "from training.trainer import SpeakerTrainer, create_training_config\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initialize Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize database and audio processor\n",
        "db = SpeakerDatabase('../speaker_recognition.db')\n",
        "processor = AudioProcessor()\n",
        "\n",
        "print(\"Components initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Explore Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all speakers\n",
        "speakers_df = db.get_all_speakers()\n",
        "print(f\"Total speakers: {len(speakers_df)}\")\n",
        "speakers_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Audio Processing Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate sample audio for demonstration\n",
        "sample_rate = 16000\n",
        "duration = 3.0\n",
        "t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "\n",
        "# Create a simple sine wave (mock voice)\n",
        "frequency = 440  # A4 note\n",
        "audio = np.sin(2 * np.pi * frequency * t) * 0.3\n",
        "\n",
        "# Add some noise to make it more realistic\n",
        "noise = np.random.normal(0, 0.05, len(audio))\n",
        "audio += noise\n",
        "\n",
        "print(f\"Generated audio: {len(audio)} samples, {duration} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features\n",
        "mfcc_features = processor.extract_mfcc(audio)\n",
        "mel_features = processor.extract_mel_spectrogram(audio)\n",
        "\n",
        "print(f\"MFCC shape: {mfcc_features.shape}\")\n",
        "print(f\"Mel spectrogram shape: {mel_features.shape}\")\n",
        "\n",
        "# Visualize features\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "# Plot MFCC\n",
        "im1 = ax1.imshow(mfcc_features, aspect='auto', origin='lower')\n",
        "ax1.set_title('MFCC Features')\n",
        "ax1.set_ylabel('MFCC Coefficient')\n",
        "plt.colorbar(im1, ax=ax1)\n",
        "\n",
        "# Plot Mel Spectrogram\n",
        "im2 = ax2.imshow(mel_features, aspect='auto', origin='lower')\n",
        "ax2.set_title('Mel Spectrogram')\n",
        "ax2.set_ylabel('Mel Band')\n",
        "ax2.set_xlabel('Time Frame')\n",
        "plt.colorbar(im2, ax=ax2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}